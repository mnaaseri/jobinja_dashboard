{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3DdXHrNPYdr",
        "outputId": "f111094f-686b-443c-ced0-f8ec572e2205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Collecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=766c0bccff0134523087d84f00c89ac96d0bc68f7bb8ed35e71f746e5a07404a\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, safetensors, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 sentence_transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.14.1 transformers-4.35.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "89kCSd1mc6Qd"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jE-Ik6oMoYvW"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Jobinja - Processed.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGv3gQVFbYgT"
      },
      "source": [
        "##Build Courps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "lSIiTj42WkTM"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from hazm import *\n",
        "normalizer = Normalizer()\n",
        "\n",
        "def build_corpus(df):\n",
        "\t\tcorpus = []\n",
        "\t\tfor i in range(len(df)):\n",
        "\t\t\t\tnews = str(df['Job Position'][i])\n",
        "\t\t\t\tnews = normalizer.normalize(news)\n",
        "\t\t\t\tnews = re.sub(r\"\\n\", \" \", news)\n",
        "\t\t\t\tnews = re.sub(r\"\\t\", \" \", news)\n",
        "\t\t\t\tnews = re.sub(r'\\u200c', \" \", news)\n",
        "\t\t\t\tnews = re.sub(r'[^\\w\\s]+', \" \", news)\n",
        "\t\t\t\tnews = re.sub(r'<[^>]+>', \" \", news)\n",
        "\t\t\t\tnews = re.sub(' +', ' ', news)\n",
        "\t\t\t\tcorpus.append(news[:500])\n",
        "\t\treturn corpus\n",
        "corpus = build_corpus(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Embeddings"
      ],
      "metadata": {
        "id": "aLTQPoYxDx6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "aPC8p3luO2U8"
      },
      "outputs": [],
      "source": [
        "embedding_model = 'intfloat/multilingual-e5-large'\n",
        "embedder = SentenceTransformer(embedding_model)\n",
        "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search in Corpus"
      ],
      "metadata": {
        "id": "YQK4pgw-EJIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store scores and indices for each query\n",
        "threshold_percentage = 0.04\n",
        "all_scores = []\n",
        "all_indices = []\n",
        "\n",
        "queries = [\"به دنبال شغل هایی مثل متخصص هوش مصنوعی، پردازش تصویر، پردازش  متن، پردازش صوت، برنامه نویسی پایتون، تحلیل داده و دانشمند داده می گردم\"]\n",
        "\n",
        "for query in queries:\n",
        "    # Encode the user query\n",
        "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarity and find the top-k results\n",
        "    top_k = min(200, len(corpus))\n",
        "    scores = []\n",
        "    indices = []\n",
        "\n",
        "    for i, emb in enumerate(corpus_embeddings):\n",
        "        cos_score = util.pytorch_cos_sim(query_embedding, emb)[0]\n",
        "        scores.append(cos_score.item())  # Convert tensor to a scalar\n",
        "        indices.append(i)\n",
        "\n",
        "    # Sort by scores\n",
        "    sorted_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
        "\n",
        "    query_scores = []\n",
        "    query_indices = []\n",
        "    highest_score = max(scores)\n",
        "    threshold = (1 - threshold_percentage) * highest_score  # Set threshold as 2 percent below the highest score\n",
        "\n",
        "    for i in sorted_indices:\n",
        "        score = scores[i]\n",
        "        if score >= threshold:\n",
        "            idx = indices[i]\n",
        "            query_scores.append(score)\n",
        "            query_indices.append(idx)\n",
        "\n",
        "    all_scores.append(query_scores)\n",
        "    all_indices.append(query_indices)\n",
        "\n",
        "# Return the highest results for each query\n",
        "results = []\n",
        "for query, scores, indices in zip(queries, all_scores, all_indices):\n",
        "    query_results = []\n",
        "    for score, idx in zip(scores, indices):\n",
        "        result = {\n",
        "            'Job Position': corpus[idx][:50],\n",
        "            'Score': score\n",
        "        }\n",
        "        query_results.append(result)\n",
        "        print(result)\n",
        "\n",
        "    results.append(query_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBaoHC0ho6Dl",
        "outputId": "e8fcf3ae-7763-4623-fff7-d8b165d39cd2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Job Position': 'استخدام متخصص هوش مصنوعی پایتون ', 'Score': 0.8960745334625244}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی', 'Score': 0.8868563175201416}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی', 'Score': 0.8868563175201416}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی', 'Score': 0.8868562579154968}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی', 'Score': 0.8868562579154968}\n",
            "{'Job Position': 'استخدام کارشناس مدیریت پروژه هوش مصنوعی و علم داده', 'Score': 0.8856395483016968}\n",
            "{'Job Position': 'استخدام متخصص فناوری هوش مصنوعی', 'Score': 0.8828755617141724}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی AI Developer ', 'Score': 0.8828009366989136}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی', 'Score': 0.8802425861358643}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی', 'Score': 0.8802425861358643}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی', 'Score': 0.8802425861358643}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی', 'Score': 0.8802425861358643}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی', 'Score': 0.8802425861358643}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی آقا ', 'Score': 0.8800738453865051}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی مشهد ', 'Score': 0.8794760704040527}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی مشهد ', 'Score': 0.8794760704040527}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی مشهد ', 'Score': 0.8794760704040527}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی مشهد ', 'Score': 0.8794759511947632}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون مسلط به پردازش زبان طبی', 'Score': 0.8793731331825256}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی بینایی کامپیوتر ', 'Score': 0.8778601288795471}\n",
            "{'Job Position': 'استخدام برنامه نویس سیستم های هوش مصنوعی', 'Score': 0.876627504825592}\n",
            "{'Job Position': 'استخدام توسعه دهنده ارشد پایتون آشنا به هوش مصنوعی', 'Score': 0.8753317594528198}\n",
            "{'Job Position': 'استخدام برنامه نویس هوش مصنوعی', 'Score': 0.8749419450759888}\n",
            "{'Job Position': 'استخدام برنامه نویس هوش مصنوعی', 'Score': 0.8749419450759888}\n",
            "{'Job Position': 'استخدام برنامه نویس هوش مصنوعی', 'Score': 0.8749418258666992}\n",
            "{'Job Position': 'استخدام پژوهشگر هوش مصنوعی', 'Score': 0.8745049238204956}\n",
            "{'Job Position': 'استخدام کارشناس علم داده هوش تجاری ', 'Score': 0.8742926120758057}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده و هوش تجاری', 'Score': 0.8742690682411194}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده و هوش تجاری', 'Score': 0.8742690682411194}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده و هوش تجاری', 'Score': 0.8742689490318298}\n",
            "{'Job Position': 'استخدام برنامه نویس هوش مصنوعی AI ', 'Score': 0.8727121949195862}\n",
            "{'Job Position': 'استخدام برنامه نویس هوش مصنوعی AI ', 'Score': 0.8727120757102966}\n",
            "{'Job Position': 'استخدام برنامه نویس هوش مصنوعی AI ', 'Score': 0.8727120757102966}\n",
            "{'Job Position': 'استخدام کارشناس ارشد هوش مصنوعی', 'Score': 0.8722646236419678}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی کرج ', 'Score': 0.8711555004119873}\n",
            "{'Job Position': 'استخدام برنامه نویس هوش مصنوعی آقا ', 'Score': 0.871131956577301}\n",
            "{'Job Position': 'استخدام کارشناس ارشد مهندسی داده و هوش تجاری', 'Score': 0.8697115778923035}\n",
            "{'Job Position': 'استخدام کارشناس توسعه نرم افزار در حوزه هوش مصنوعی', 'Score': 0.8695993423461914}\n",
            "{'Job Position': 'استخدام کارآموز برنامه نویس هوش مصنوعی AI ', 'Score': 0.86948162317276}\n",
            "{'Job Position': 'استخدام کارشناس ارشد پردازش سیگنال مخابراتی هوش مص', 'Score': 0.8693082928657532}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون الگوریتم های معاملاتی ', 'Score': 0.8686469793319702}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی قم ', 'Score': 0.8683291077613831}\n",
            "{'Job Position': 'استخدام مشاور یادگیری ماشین و تحلیل داده Machine L', 'Score': 0.8675901293754578}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی بهینه سازی مدل ها مشهد ', 'Score': 0.867357075214386}\n",
            "{'Job Position': 'استخدام برنامه نویس پردازش تصویر', 'Score': 0.8672483563423157}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی دورکاری ', 'Score': 0.867102861404419}\n",
            "{'Job Position': 'استخدام متخصص هوش مصنوعی دورکاری ', 'Score': 0.867102861404419}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی قزوین ', 'Score': 0.866666316986084}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی امریه آقا ', 'Score': 0.8665229082107544}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663499355316162}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663499355316162}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663499355316162}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663499355316162}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663499355316162}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663498759269714}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663498759269714}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663498759269714}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663498163223267}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663498163223267}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل داده', 'Score': 0.8663498163223267}\n",
            "{'Job Position': 'استخدام کارشناس هوش مصنوعی کرج ', 'Score': 0.8661841154098511}\n",
            "{'Job Position': 'استخدام برنامه نویس هوش مصنوعی AI مشهد ', 'Score': 0.865958034992218}\n",
            "{'Job Position': 'استخدام برنامه نویس هوش مصنوعی AI مشهد ', 'Score': 0.865958034992218}\n",
            "{'Job Position': 'استخدام توسعه دهنده پایتون', 'Score': 0.8658989667892456}\n",
            "{'Job Position': 'استخدام کارشناس علم داده', 'Score': 0.8658793568611145}\n",
            "{'Job Position': 'استخدام کارشناس علم داده', 'Score': 0.8658793568611145}\n",
            "{'Job Position': 'استخدام مدرس هوش مصنوعی', 'Score': 0.8658401966094971}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون', 'Score': 0.8653507232666016}\n",
            "{'Job Position': 'استخدام کارشناس علوم داده', 'Score': 0.864718496799469}\n",
            "{'Job Position': 'استخدام کارآموز تحلیل داده و هوش تجاری', 'Score': 0.864067554473877}\n",
            "{'Job Position': 'استخدام کارشناس مهندسی داده', 'Score': 0.8636643290519714}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python آقا ', 'Score': 0.8634275197982788}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python آقا ', 'Score': 0.8634275197982788}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python آقا ', 'Score': 0.8634275197982788}\n",
            "{'Job Position': 'استخدام کارآموز هوش مصنوعی', 'Score': 0.8632484078407288}\n",
            "{'Job Position': 'استخدام کارآموز هوش مصنوعی', 'Score': 0.8632484078407288}\n",
            "{'Job Position': 'استخدام کارآموز هوش مصنوعی', 'Score': 0.8632484078407288}\n",
            "{'Job Position': 'استخدام کارشناس داده کاوی', 'Score': 0.8630526065826416}\n",
            "{'Job Position': 'استخدام مهندس داده ها Data Engineering ', 'Score': 0.8630387187004089}\n",
            "{'Job Position': 'استخدام تحلیلگر داده', 'Score': 0.8626333475112915}\n",
            "{'Job Position': 'استخدام مدیر محصول هوش مصنوعی AI Product Manager ', 'Score': 0.8621655702590942}\n",
            "{'Job Position': 'استخدام کارشناس هوش تجاری عملیات BI ', 'Score': 0.8617933392524719}\n",
            "{'Job Position': 'استخدام کارشناس دیجیتال', 'Score': 0.861656129360199}\n",
            "{'Job Position': 'استخدام طراح سخت افزار الکترونیک دیجیتال طراحی سیس', 'Score': 0.8614116907119751}\n",
            "{'Job Position': 'استخدام کارشناس عملیات سامانه های هوش تجاری', 'Score': 0.8613959550857544}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python ', 'Score': 0.8611270189285278}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python ', 'Score': 0.8611270189285278}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python ', 'Score': 0.8611270189285278}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python ', 'Score': 0.8611270189285278}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python ', 'Score': 0.8611270189285278}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python ', 'Score': 0.8611269593238831}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python ', 'Score': 0.8611269593238831}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python ', 'Score': 0.8611269593238831}\n",
            "{'Job Position': 'استخدام برنامه نویس پایتون Python ', 'Score': 0.8611269593238831}\n",
            "{'Job Position': 'استخدام کارشناس تحلیل بورس و ارز دیجیتال ', 'Score': 0.861027181148529}\n",
            "{'Job Position': 'استخدام توسعه دهنده ارشد پایتون Senior Python Deve', 'Score': 0.860910177230835}\n",
            "{'Job Position': 'استخدام کارشناس داده نمایی Data visualization ', 'Score': 0.8608496189117432}\n",
            "{'Job Position': 'استخدام کارشناس برنامه ریزی و تحلیل داده', 'Score': 0.8607733249664307}\n",
            "{'Job Position': 'استخدام توسعه دهنده پایتون Python Backend Develope', 'Score': 0.8607412576675415}\n",
            "{'Job Position': 'استخدام کارآموز هوش مصنوعی قم ', 'Score': 0.8603891730308533}\n",
            "{'Job Position': 'استخدام کارشناس هوش تجاری Power BI ', 'Score': 0.8602983951568604}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jPW8Mk6114_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}